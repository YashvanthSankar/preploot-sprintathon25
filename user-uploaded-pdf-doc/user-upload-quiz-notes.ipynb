{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873dcf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "MODEL = \"gemini-2.5-flash-lite\"\n",
    "db_name = \"vector_db\"\n",
    "\n",
    "folder = \"data_files\"\n",
    "pdf_files = glob.glob(f\"{folder}/*.pdf\")\n",
    "\n",
    "STATE_FILE = \"processed_files.json\"\n",
    "processed_files = {}\n",
    "\n",
    "if os.path.exists(STATE_FILE):\n",
    "    with open(STATE_FILE, \"r\") as f:\n",
    "        processed_files = json.load(f)\n",
    "\n",
    "def get_text_from_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        content = page.extract_text()\n",
    "        if content:\n",
    "            text += content + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def check_new_files(folder=\"data_files\"):\n",
    "    pdf_files = glob.glob(f\"{folder}/*.pdf\")\n",
    "\n",
    "    # detect removed files\n",
    "    removed_files = [f for f in list(processed_files.keys()) if f not in pdf_files]\n",
    "    for f in removed_files:\n",
    "        print(f\"File removed: {f}\")\n",
    "        processed_files.pop(f, None)\n",
    "\n",
    "    # detect new/updated files\n",
    "    new_files = []\n",
    "    for file in pdf_files:\n",
    "        last_modified = os.path.getmtime(file)\n",
    "        if (file not in processed_files) or (processed_files[file] < last_modified):\n",
    "            new_files.append(file)\n",
    "            processed_files[file] = last_modified\n",
    "\n",
    "    # âœ… save state immediately after updating processed_files\n",
    "    save_state()\n",
    "\n",
    "    return new_files, removed_files\n",
    "\n",
    "\n",
    "def save_state():\n",
    "    with open(STATE_FILE, \"w\") as f:\n",
    "        json.dump(processed_files, f)   \n",
    "\n",
    "def store_chroma_function():\n",
    "    new_files, removed_files = check_new_files()\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\", google_api_key=api_key)\n",
    "\n",
    "    # load existing DB if it exists, otherwise create later\n",
    "    vectorstore = None\n",
    "    if os.path.exists(db_name):\n",
    "        vectorstore = Chroma(persist_directory=db_name, embedding_function=embeddings)\n",
    "\n",
    "    # ðŸ”¥ Delete vectors for removed files\n",
    "    if removed_files and vectorstore:\n",
    "        for f in removed_files:\n",
    "            print(f\"Deleting vectors for: {f}\")\n",
    "            vectorstore.delete(where={\"source\": f})\n",
    "    \n",
    "    # Check if there are any PDF files at all\n",
    "    pdf_files = glob.glob(f\"{folder}/*.pdf\")\n",
    "    if not pdf_files:\n",
    "        print(\"No PDF files in the directory.\")\n",
    "        if vectorstore:\n",
    "            print(\"Cleaning up vector store...\")\n",
    "            vectorstore._collection.delete(where={})  # Clear all documents\n",
    "            # Close the connection to allow deletion\n",
    "            vectorstore._client._conn.close()\n",
    "            vectorstore = None\n",
    "            \n",
    "        # Delete the vector store directory and its contents\n",
    "        if os.path.exists(db_name):\n",
    "            print(f\"Removing {db_name} directory...\")\n",
    "            import shutil\n",
    "            shutil.rmtree(db_name)\n",
    "            \n",
    "        if os.path.exists(STATE_FILE):\n",
    "            print(\"Removing state file...\")\n",
    "            os.remove(STATE_FILE)  # Clear the processing state\n",
    "        return None\n",
    "\n",
    "    # no new files â†’ just return\n",
    "    if not new_files:\n",
    "        print(\"No new files, skipping embeddings.\")\n",
    "        return vectorstore\n",
    "\n",
    "    # otherwise, process new files\n",
    "    print(\"New/updated files found:\", new_files)\n",
    "    docs = []\n",
    "    for f in new_files:\n",
    "        text = get_text_from_pdf(f)\n",
    "        docs.append(Document(page_content=text, metadata={\"source\": f}))\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "    if vectorstore:\n",
    "        vectorstore.add_documents(chunks)\n",
    "    else:\n",
    "        vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "\n",
    "    save_state()\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff5d84c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File removed: data_files\\Attention Is All Need You.pdf\n",
      "Deleting vectors for: data_files\\Attention Is All Need You.pdf\n",
      "New/updated files found: ['data_files\\\\Algorithm Notes.pdf']\n",
      "Number of chunks in vectorstore: 5\n"
     ]
    }
   ],
   "source": [
    "vectorstore = store_chroma_function()\n",
    "if vectorstore is None:\n",
    "    print(\"No documents in DB yet. Please add some PDFs to data_files.\")\n",
    "    exit()\n",
    "all_docs = vectorstore.get()  # may differ slightly depending on version\n",
    "texts = all_docs['documents']  # list of document objects\n",
    "\n",
    "print(f\"Number of chunks in vectorstore: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a6f469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import this module and call generate_quiz_from_vectorstore() with your vectorstore!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Gemini client\n",
    "client = genai.Client()\n",
    "\n",
    "def deduplicate_chunks(chunks, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Deduplicate similar chunks using TF-IDF and cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of document chunks (strings)\n",
    "        threshold: Similarity threshold (0-1) above which chunks are considered duplicates\n",
    "    \n",
    "    Returns:\n",
    "        List of deduplicated chunks\n",
    "    \"\"\"\n",
    "    if len(chunks) <= 1:\n",
    "        return chunks\n",
    "    \n",
    "    # Create TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(chunks)\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    similarities = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # Keep track of which chunks to keep\n",
    "    keep_indices = []\n",
    "    seen = set()\n",
    "    \n",
    "    for i in range(len(chunks)):\n",
    "        if i in seen:\n",
    "            continue\n",
    "        keep_indices.append(i)\n",
    "        # Mark similar chunks as seen\n",
    "        for j in range(i + 1, len(chunks)):\n",
    "            if similarities[i][j] > threshold:\n",
    "                seen.add(j)\n",
    "    \n",
    "    return [chunks[i] for i in keep_indices]\n",
    "\n",
    "def batch_chunks(chunks, batch_size=5):\n",
    "    \"\"\"\n",
    "    Batch chunks together to reduce API calls.\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of text chunks\n",
    "        batch_size: Number of chunks to combine per batch\n",
    "    \n",
    "    Returns:\n",
    "        List of batched chunks\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        # Combine chunks with separators\n",
    "        combined = \"\\n\\n--- SECTION ---\\n\\n\".join(batch)\n",
    "        batches.append(combined)\n",
    "    return batches\n",
    "\n",
    "def clean_json_response(response_text):\n",
    "    \"\"\"\n",
    "    Extract and clean JSON from Gemini response.\n",
    "    \"\"\"\n",
    "    # Remove markdown code blocks if present\n",
    "    response_text = re.sub(r'```json\\s*', '', response_text)\n",
    "    response_text = re.sub(r'```\\s*', '', response_text)\n",
    "    \n",
    "    # Try to find JSON array in the response\n",
    "    match = re.search(r'\\[.*\\]', response_text, re.DOTALL)\n",
    "    if match:\n",
    "        response_text = match.group(0)\n",
    "    \n",
    "    return response_text.strip()\n",
    "\n",
    "def generate_quiz_from_batch(batch_text, batch_index, total_batches):\n",
    "    \"\"\"\n",
    "    Generate quiz questions from a batch of chunks using Gemini.\n",
    "    \"\"\"\n",
    "    transcript_prompt = f\"\"\"\n",
    "You are a teacher creating quizzes from lecture transcripts. Using the text below (which contains multiple sections separated by \"--- SECTION ---\"), generate a quiz with questions covering all important topics across ALL sections. The quiz should include **multiple-choice questions (MCQs)** only. Each question should have:\n",
    "\n",
    "1. A \"question\" string.\n",
    "2. An \"options\" list with exactly 4 options.\n",
    "3. An \"answer\" string indicating the correct option.\n",
    "4. A \"difficulty\" string which can be \"easy\", \"medium\", or \"hard\".\n",
    "5. An \"explanation\" string for the correct answer.\n",
    "\n",
    "Generate questions from each distinct topic/concept across all sections. Output the quiz strictly in JSON format like this:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"question\": \"Example question?\",\n",
    "    \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"],\n",
    "    \"answer\": \"Option B\",\n",
    "    \"difficulty\": \"medium\",\n",
    "    \"explanation\": \"Explanation for the correct answer.\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "Make sure the output is parsable. Do not include any other characters other than the structure I have specified.\n",
    "\n",
    "**Transcript:**\n",
    "\"{batch_text}\"\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Generating questions from batch {batch_index + 1}/{total_batches}...\")\n",
    "        \n",
    "        content = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash-lite\",\n",
    "            contents=transcript_prompt\n",
    "        )\n",
    "        \n",
    "        response_text = content.text\n",
    "        cleaned_response = clean_json_response(response_text)\n",
    "        \n",
    "        # Parse JSON\n",
    "        questions = json.loads(cleaned_response)\n",
    "        \n",
    "        print(f\"  âœ“ Generated {len(questions)} question(s)\")\n",
    "        return questions\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"  âœ— JSON parsing error for batch {batch_index + 1}: {e}\")\n",
    "        print(f\"  Response preview: {response_text[:200]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error generating quiz for batch {batch_index + 1}: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_quiz_from_vectorstore(vectorstore, output_file=\"quiz_output.json\", \n",
    "                                   similarity_threshold=0.85, batch_size=7):\n",
    "    \"\"\"\n",
    "    Generate quiz questions from all chunks in the vectorstore.\n",
    "    \n",
    "    Args:\n",
    "        vectorstore: Initialized Chroma vectorstore\n",
    "        output_file: Path to save the final JSON quiz\n",
    "        similarity_threshold: Threshold for deduplication (0-1)\n",
    "        batch_size: Number of chunks to combine per API call (default: 5)\n",
    "                   Increase to reduce API calls, decrease if hitting token limits\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Starting Quiz Generation from Vectorstore\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Retrieve all documents from vectorstore\n",
    "    print(\"\\n1. Retrieving all documents from vectorstore...\")\n",
    "    all_docs = vectorstore.get()\n",
    "    \n",
    "    if not all_docs or 'documents' not in all_docs:\n",
    "        print(\"No documents found in vectorstore!\")\n",
    "        return\n",
    "    \n",
    "    chunks = all_docs['documents']\n",
    "    print(f\"   Found {len(chunks)} total chunks\")\n",
    "    \n",
    "    # Deduplicate chunks\n",
    "    print(f\"\\n2. Deduplicating chunks (threshold={similarity_threshold})...\")\n",
    "    unique_chunks = deduplicate_chunks(chunks, threshold=similarity_threshold)\n",
    "    print(f\"   Kept {len(unique_chunks)} unique chunks (removed {len(chunks) - len(unique_chunks)} duplicates)\")\n",
    "    \n",
    "    # Batch chunks together\n",
    "    print(f\"\\n3. Batching chunks (batch_size={batch_size})...\")\n",
    "    batched_chunks = batch_chunks(unique_chunks, batch_size=batch_size)\n",
    "    print(f\"   Created {len(batched_chunks)} batches\")\n",
    "    print(f\"   API calls reduced from {len(unique_chunks)} to {len(batched_chunks)} ({len(unique_chunks)/len(batched_chunks):.1f}x reduction)\")\n",
    "    \n",
    "    # Generate quiz from each batch\n",
    "    print(f\"\\n4. Generating quiz questions...\")\n",
    "    all_questions = []\n",
    "    \n",
    "    for idx, batch in enumerate(batched_chunks):\n",
    "        questions = generate_quiz_from_batch(batch, idx, len(batched_chunks))\n",
    "        all_questions.extend(questions)\n",
    "    \n",
    "    # Save to JSON file\n",
    "    print(f\"\\n5. Saving quiz to {output_file}...\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_questions, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"âœ“ Quiz generation complete!\")\n",
    "    print(f\"  Total questions generated: {len(all_questions)}\")\n",
    "    print(f\"  Output saved to: {output_file}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize your vectorstore (adjust parameters as needed)\n",
    "    # Example:\n",
    "    # from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "    # embeddings = HuggingFaceEmbeddings()\n",
    "    # vectorstore = Chroma(\n",
    "    #     persist_directory=\"./chroma_db\",\n",
    "    #     embedding_function=embeddings,\n",
    "    #     collection_name=\"your_collection\"\n",
    "    # )\n",
    "    \n",
    "    # Or if you already have it initialized:\n",
    "    # vectorstore = your_existing_vectorstore\n",
    "    \n",
    "    # Generate quiz with batching\n",
    "    # questions = generate_quiz_from_vectorstore(\n",
    "    #     vectorstore=vectorstore,\n",
    "    #     output_file=\"final_quiz.json\",\n",
    "    #     similarity_threshold=0.85,\n",
    "    #     batch_size=5  # Combine 5 chunks per API call\n",
    "    # )\n",
    "    \n",
    "    print(\"Import this module and call generate_quiz_from_vectorstore() with your vectorstore!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86fe1fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting Quiz Generation from Vectorstore\n",
      "============================================================\n",
      "\n",
      "1. Retrieving all documents from vectorstore...\n",
      "   Found 5 total chunks\n",
      "\n",
      "2. Deduplicating chunks (threshold=0.85)...\n",
      "   Kept 5 unique chunks (removed 0 duplicates)\n",
      "\n",
      "3. Batching chunks (batch_size=7)...\n",
      "   Created 1 batches\n",
      "   API calls reduced from 5 to 1 (5.0x reduction)\n",
      "\n",
      "4. Generating quiz questions...\n",
      "Generating questions from batch 1/1...\n",
      "  âœ“ Generated 15 question(s)\n",
      "\n",
      "5. Saving quiz to quiz_output.json...\n",
      "\n",
      "============================================================\n",
      "âœ“ Quiz generation complete!\n",
      "  Total questions generated: 15\n",
      "  Output saved to: quiz_output.json\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question': 'Which of the following is NOT a characteristic of a proper algorithm?',\n",
       "  'options': ['Correctness', 'Deterministic', 'Finite', 'Complex'],\n",
       "  'answer': 'Complex',\n",
       "  'difficulty': 'easy',\n",
       "  'explanation': 'A proper algorithm should be simple and communicable, not complex.'},\n",
       " {'question': 'Which of the following is NOT a major factor determining program performance?',\n",
       "  'options': ['Algorithm and Data Structures',\n",
       "   'Hardware',\n",
       "   'Programming Language',\n",
       "   'Compiler'],\n",
       "  'answer': 'Hardware',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': 'Algorithm and Data Structures are major factors; Hardware, Programming Language, and Compiler are platform dependent.'},\n",
       " {'question': 'What is the primary question asked in Algorithm Analysis?',\n",
       "  'options': ['How many lines of code does it have?',\n",
       "   'How fast is my algorithm as a function of input size?',\n",
       "   'How much memory does it use?',\n",
       "   'How much power does it consume?'],\n",
       "  'answer': 'How fast is my algorithm as a function of input size?',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': 'Algorithm analysis focuses on understanding how the execution time of an algorithm scales with the input size.'},\n",
       " {'question': 'What does Step-Count Analysis primarily involve?',\n",
       "  'options': ['Measuring the exact execution time of an algorithm.',\n",
       "   'Counting the number of steps/operations an algorithm takes.',\n",
       "   'Analyzing the memory usage of an algorithm.',\n",
       "   'Comparing the algorithm to other algorithms.'],\n",
       "  'answer': 'Counting the number of steps/operations an algorithm takes.',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': 'Step-count analysis focuses on quantifying the operations performed as a function of input size.'},\n",
       " {'question': 'What is the purpose of Sensitivity Analysis?',\n",
       "  'options': ['To measure the exact running time of an algorithm.',\n",
       "   'To determine how sensitive the running time is to the input size.',\n",
       "   'To model memory delays.',\n",
       "   'To ignore lower-order terms.'],\n",
       "  'answer': 'To determine how sensitive the running time is to the input size.',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': 'Sensitivity analysis investigates how the execution time changes as the input size increases.'},\n",
       " {'question': 'If lim nâ†’âˆž f(n)/g(n) = âˆž, what is the relationship between f(n) and g(n)?',\n",
       "  'options': ['f(n) âˆˆ o(g(n))',\n",
       "   'f(n) âˆˆ Î˜(g(n))',\n",
       "   'f(n) âˆˆ Ï‰(g(n))',\n",
       "   'f(n) âˆˆ O(g(n))'],\n",
       "  'answer': 'f(n) âˆˆ Ï‰(g(n))',\n",
       "  'difficulty': 'hard',\n",
       "  'explanation': 'If the limit is infinity, f(n) grows strictly faster than g(n), indicating little-omega notation.'},\n",
       " {'question': 'What is the purpose of recurrence relations in algorithm analysis?',\n",
       "  'options': ['To determine the exact execution time.',\n",
       "   'To express the nth term with reference to previous term(s).',\n",
       "   'To ignore machine specific constants.',\n",
       "   'To compare to other algorithms'],\n",
       "  'answer': 'To express the nth term with reference to previous term(s).',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': 'Recurrence relations describe the execution time of recursive algorithms in terms of calls to themselves.'},\n",
       " {'question': \"In the standard form of divide and conquer recurrences T(n) = aT(n/b) + f(n), what does 'a' represent?\",\n",
       "  'options': ['Branching factor',\n",
       "   'Reduction factor',\n",
       "   'Overhead cost',\n",
       "   'Input size'],\n",
       "  'answer': 'Branching factor',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': \"'a' indicates the number of subproblems created in each recursive step.\"},\n",
       " {'question': 'In the context of loop invariants, what must be true before the first iteration?',\n",
       "  'options': ['The loop must terminate.',\n",
       "   'The loop invariant must be true.',\n",
       "   'The loop must execute for a set number of times.',\n",
       "   'The loop must take more than a set amount of time.'],\n",
       "  'answer': 'The loop invariant must be true.',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': 'The loop invariant is a condition that must hold true before the loop starts.'},\n",
       " {'question': 'What is the time complexity of Heapsort?',\n",
       "  'options': ['O(n)', 'O(log n)', 'O(n log n)', 'O(n^2)'],\n",
       "  'answer': 'O(n log n)',\n",
       "  'difficulty': 'easy',\n",
       "  'explanation': 'Heapsort has a time complexity of O(n log n).'},\n",
       " {'question': 'What is the time complexity of the partition step in Quick Sort?',\n",
       "  'options': ['O(n)', 'O(log n)', 'O(n log n)', 'O(n^2)'],\n",
       "  'answer': 'O(n)',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': 'The partition step in quicksort, which rearranges elements, runs in linear time with respect to the number of elements.'},\n",
       " {'question': \"In the Greedy Method, what is the 'goal' in the optimization problem setup?\",\n",
       "  'options': ['The set of instances',\n",
       "   'The set of feasible solutions',\n",
       "   'The objective function',\n",
       "   'Maximize or minimize'],\n",
       "  'answer': 'Maximize or minimize',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': 'The goal specifies whether the problem is to find a solution that maximizes or minimizes the objective function.'},\n",
       " {'question': 'Which of the following is a characteristic of the Greedy Algorithm Strategy?',\n",
       "  'options': ['Makes choices based on all the future consequences',\n",
       "   'Makes locally optimal choices',\n",
       "   'Chooses a random solution.',\n",
       "   'Only works with small inputs.'],\n",
       "  'answer': 'Makes locally optimal choices',\n",
       "  'difficulty': 'medium',\n",
       "  'explanation': 'Greedy algorithms make the choice that seems best at the current moment, without considering the overall effect.'},\n",
       " {'question': 'Which is the correct approach for the Coin Change Problem to work?',\n",
       "  'options': ['Take the smallest coin possible.',\n",
       "   'Take the largest coin.',\n",
       "   'Alternate between largest and smallest coins.',\n",
       "   'Take the coins at random.'],\n",
       "  'answer': 'Take the largest coin.',\n",
       "  'difficulty': 'easy',\n",
       "  'explanation': 'The classic coin change problem uses the greedy method by taking the largest coin possible.'},\n",
       " {'question': 'For which of the following does the greedy strategy provide an optimal solution?',\n",
       "  'options': ['Coin Change Problem (with all coin values).',\n",
       "   'Container Loading Problem.',\n",
       "   'Job Scheduling with Deadlines.',\n",
       "   'All of the above.'],\n",
       "  'answer': 'All of the above.',\n",
       "  'difficulty': 'hard',\n",
       "  'explanation': 'Greedy method works optimally for those 3 problems.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_quiz_from_vectorstore(vectorstore=vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b53165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
